# ğŸ“Š EDA Platform - Exploratory Data Analysis Tool

<div align="center">

![EDA Platform](https://img.shields.io/badge/EDA-Platform-blue?style=for-the-badge&logo=chart-bar)
![Next.js](https://img.shields.io/badge/Next.js-15-black?style=for-the-badge&logo=next.js)
![Supabase](https://img.shields.io/badge/Supabase-Database-green?style=for-the-badge&logo=supabase)
![TypeScript](https://img.shields.io/badge/TypeScript-5-blue?style=for-the-badge&logo=typescript)

**A powerful web application for automated Exploratory Data Analysis (EDA) of CSV datasets**

[ğŸš€ Live Demo](#demo) â€¢ [ğŸ“– Documentation](#features) â€¢ [ğŸ› ï¸ Setup](#setup) â€¢ [ğŸ“Š Screenshots](#screenshots)

</div>

---

## ğŸ¯ Overview

The **EDA Platform** is a comprehensive web application designed to automate and streamline the process of Exploratory Data Analysis (EDA) for CSV datasets. Built with modern web technologies, it provides an intuitive interface for data scientists, analysts, and researchers to quickly understand their data through automated statistical analysis, visualizations, and AI-powered insights.

### ğŸŒŸ Key Highlights

- **ğŸ¤– Automated EDA**: Upload any CSV file and get instant comprehensive analysis
- **ğŸ“ˆ Rich Visualizations**: Interactive charts, histograms, scatter plots, and correlation heatmaps
- **ğŸ§  AI-Powered Chatbot**: Natural language queries about your data
- **ğŸ“„ PDF Reports**: Generate professional analysis reports
- **âš¡ High Performance**: Optimized for large datasets with lazy loading and caching
- **ğŸ¨ Modern UI**: Clean, responsive design with dark/light mode support

---

## âœ¨ Features

### ğŸ“Š **Automated Data Analysis**
- **Summary Statistics**: Mean, median, standard deviation, quartiles for numeric columns
- **Data Type Detection**: Automatic identification of numeric, text, and categorical data
- **Missing Value Analysis**: Comprehensive missing data detection and visualization
- **Correlation Analysis**: Pearson correlation matrix with heatmap visualization

### ğŸ“ˆ **Advanced Visualizations**
- **Distribution Charts**: Histograms for numeric data distribution analysis
- **Relationship Analysis**: Scatter plots for correlation exploration
- **Data Quality Charts**: Missing value patterns and data completeness metrics
- **Interactive Charts**: Built with Recharts for smooth user experience

### ğŸ¤– **AI-Powered Data Assistant**
- **Natural Language Queries**: Ask questions about your data in plain English
- **Intelligent Insights**: Get automated insights and recommendations
- **Context-Aware Responses**: AI understands your specific dataset structure
- **Suggested Questions**: Pre-generated questions to help you explore your data

### ğŸ“„ **Professional Reporting**
- **PDF Export**: Generate comprehensive analysis reports
- **Print-Friendly**: Optimized layouts for both screen and print
- **Customizable**: Include/exclude sections based on your needs
- **Professional Formatting**: Clean, structured reports ready for presentation

### âš¡ **Performance & Scalability**
- **Lazy Loading**: Load data on-demand to handle large datasets
- **Data Sampling**: Intelligent sampling for visualization performance
- **Caching**: In-memory caching for faster repeated access
- **Pagination**: Efficient handling of large datasets

### ğŸ¨ **User Experience**
- **Responsive Design**: Works seamlessly on desktop, tablet, and mobile
- **Dark/Light Mode**: Toggle between themes for comfortable viewing
- **Intuitive Navigation**: Clean, organized interface
- **Real-time Feedback**: Loading states and progress indicators

---

## ğŸ› ï¸ Technology Stack

### **Frontend**
- **Next.js 15** - React framework with App Router
- **TypeScript** - Type-safe development
- **Tailwind CSS** - Utility-first CSS framework
- **shadcn/ui** - Modern component library
- **Recharts** - Data visualization library
- **Lucide React** - Beautiful icons

### **Backend & Database**
- **Supabase** - Backend-as-a-Service
- **PostgreSQL** - Relational database
- **Row Level Security (RLS)** - Data security
- **Server Actions** - Server-side data processing

### **AI & Analytics**
- **Groq API** - Large Language Model integration
- **Papa Parse** - CSV parsing and processing
- **Statistical Analysis** - Custom algorithms for EDA

### **Development Tools**
- **ESLint** - Code linting
- **PostCSS** - CSS processing
- **Git** - Version control

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ 
- npm, yarn, or pnpm
- Supabase account (free tier available)

### 1. Clone the Repository
   ```bash
git clone <your-repo-url>
cd eda-platform
   ```

### 2. Install Dependencies
   ```bash
npm install
# or
yarn install
# or
pnpm install
```

### 3. Set Up Supabase
1. Create a new project at [supabase.com](https://supabase.com)
2. Go to Settings â†’ API to get your project URL and anon key
3. Create the required database tables (see [Database Setup](#database-setup))

### 4. Environment Configuration
Create a `.env.local` file in the root directory:

```env
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url
NEXT_PUBLIC_SUPABASE_PUBLISHABLE_OR_ANON_KEY=your_supabase_anon_key
GROQ_API_KEY=your_groq_api_key
```

### 5. Run the Development Server
   ```bash
npm run dev
# or
yarn dev
# or
pnpm dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

---

## ğŸ—„ï¸ Database Setup

### Required Tables

#### 1. Datasets Table
```sql
CREATE TABLE datasets (
  id SERIAL PRIMARY KEY,
  file_name TEXT NOT NULL,
  file_size INTEGER NOT NULL,
  data JSONB NOT NULL,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Enable RLS
ALTER TABLE datasets ENABLE ROW LEVEL SECURITY;

-- Allow public access for demo
CREATE POLICY "Allow all access for demo" ON datasets FOR ALL TO anon USING (true);
```

#### 2. Dataset Analyses Table
```sql
CREATE TABLE dataset_analyses (
  id SERIAL PRIMARY KEY,
  dataset_id INTEGER REFERENCES datasets(id) ON DELETE CASCADE,
  summary_stats JSONB NOT NULL,
  missing_values JSONB NOT NULL,
  column_types JSONB NOT NULL,
  correlation_matrix JSONB NOT NULL,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Enable RLS
ALTER TABLE dataset_analyses ENABLE ROW LEVEL SECURITY;

-- Allow public access for demo
CREATE POLICY "Allow all access for demo" ON dataset_analyses FOR ALL TO anon USING (true);
```

---

## ğŸ“± Usage Guide

### 1. **Upload Your Data**
- Navigate to the Upload page
- Select a CSV file from your computer
- The system will automatically parse and analyze your data

### 2. **Explore Analysis Results**
- View comprehensive summary statistics
- Examine data types and missing value patterns
- Review correlation matrices

### 3. **Visualize Your Data**
- Browse interactive charts and graphs
- Explore data distributions with histograms
- Analyze relationships with scatter plots
- Review data quality metrics

### 4. **Chat with Your Data**
- Use the AI chatbot to ask questions about your dataset
- Get insights and recommendations
- Explore suggested questions for deeper analysis

### 5. **Generate Reports**
- Create professional PDF reports
- Customize report content
- Export for presentations or documentation

---

## ğŸ—ï¸ Project Structure

```
eda-platform/
â”œâ”€â”€ app/                          # Next.js App Router
â”‚   â”œâ”€â”€ data/                     # Data analysis page
â”‚   â”œâ”€â”€ upload/                   # CSV upload page
â”‚   â”œâ”€â”€ api/                      # API routes
â”‚   â””â”€â”€ layout.tsx               # Root layout
â”œâ”€â”€ components/                   # React components
â”‚   â”œâ”€â”€ charts/                  # Chart components
â”‚   â”‚   â”œâ”€â”€ HistogramChart.tsx
â”‚   â”‚   â”œâ”€â”€ ScatterPlot.tsx
â”‚   â”‚   â”œâ”€â”€ CorrelationHeatmap.tsx
â”‚   â”‚   â””â”€â”€ MissingValuesChart.tsx
â”‚   â”œâ”€â”€ AdvancedCharts.tsx       # Main visualization component
â”‚   â”œâ”€â”€ AnalysisResults.tsx      # Analysis display
â”‚   â”œâ”€â”€ DataChatbot.tsx          # AI chatbot
â”‚   â”œâ”€â”€ OptimizedDatasetTabs.tsx # Dataset management
â”‚   â”œâ”€â”€ ReportGenerator.tsx      # PDF report generation
â”‚   â””â”€â”€ ui/                      # shadcn/ui components
â”œâ”€â”€ lib/                         # Utilities and configurations
â”‚   â”œâ”€â”€ supabase/               # Supabase client setup
â”‚   â””â”€â”€ utils.ts                # Helper functions
â””â”€â”€ app/actions/                # Server actions
    â”œâ”€â”€ analyzeData.ts          # EDA analysis logic
    â”œâ”€â”€ chatbot.ts              # AI chatbot integration
    â””â”€â”€ getDatasetData.ts       # Data fetching utilities
```

---

## ğŸ”§ Configuration

### Groq API Setup
1. Sign up at [console.groq.com](https://console.groq.com)
2. Create an API key
3. Add it to your `.env.local` file as `GROQ_API_KEY`

### Customization Options
- **Chart Colors**: Modify color schemes in chart components
- **Analysis Parameters**: Adjust statistical calculations in `analyzeData.ts`
- **UI Themes**: Customize Tailwind CSS classes
- **Report Templates**: Modify `ReportTemplate.tsx` for custom report layouts

---

## ğŸš€ Deployment

### Vercel (Recommended)
1. Push your code to GitHub
2. Connect your repository to Vercel
3. Add environment variables in Vercel dashboard
4. Deploy automatically

### Other Platforms
The application can be deployed to any platform that supports Next.js:
- Netlify
- Railway
- DigitalOcean App Platform
- AWS Amplify

---

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines
- Follow TypeScript best practices
- Use meaningful commit messages
- Add tests for new features
- Update documentation as needed

---

## ğŸ“Š Performance

### Optimizations Implemented
- **Lazy Loading**: Data loaded on-demand
- **Data Sampling**: Reduced data points for visualizations
- **Caching**: In-memory caching for repeated requests
- **Pagination**: Efficient handling of large datasets
- **Bundle Optimization**: Tree-shaking and code splitting

### Benchmarks
- **Small Datasets** (< 1,000 rows): < 2 seconds analysis time
- **Medium Datasets** (1,000-10,000 rows): < 5 seconds analysis time
- **Large Datasets** (10,000+ rows): < 10 seconds analysis time with sampling

---

## ğŸ”’ Security

### Data Protection
- **No Authentication Required**: Public demo mode for easy access
- **Row Level Security**: Database-level access control
- **Input Validation**: Sanitized CSV parsing
- **Error Handling**: Graceful error management

### Privacy
- Data is stored in your Supabase instance
- No data is sent to third-party services (except Groq for AI features)
- You maintain full control over your data

---

## ğŸ› Troubleshooting

### Common Issues

#### Build Errors
   ```bash
# Clear Next.js cache
rm -rf .next
npm run build
```

#### Supabase Connection Issues
- Verify your environment variables
- Check Supabase project status
- Ensure RLS policies are correctly configured

#### CSV Upload Issues
- Ensure file is valid CSV format
- Check file size limits
- Verify file encoding (UTF-8 recommended)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Next.js Team** - For the amazing React framework
- **Supabase Team** - For the powerful backend platform
- **shadcn/ui** - For the beautiful component library
- **Recharts** - For the excellent charting library
- **Groq** - For the fast AI inference API

---

## ğŸ“ Support

- **Documentation**: Check this README and inline code comments
- **Issues**: Open an issue on GitHub for bugs or feature requests
- **Discussions**: Use GitHub Discussions for questions and ideas

---

<div align="center">

**Built with â¤ï¸ for the data science community**

[â­ Star this repo](https://github.com/your-username/eda-platform) â€¢ [ğŸ› Report Bug](https://github.com/your-username/eda-platform/issues) â€¢ [ğŸ’¡ Request Feature](https://github.com/your-username/eda-platform/issues)

</div>